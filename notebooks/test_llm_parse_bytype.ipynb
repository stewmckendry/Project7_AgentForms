{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40995e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:10,916] [INFO] üîß Getting ready for OpenAI call...\n",
      "[2025-04-16 15:28:10,917] [INFO] üîß Loading environment variables to retrieve OpenAI API key...\n",
      "[2025-04-16 15:28:10,948] [INFO] ‚úÖ OpenAI client initialized.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from src.models.llm_responsevalidators import (\n",
    "    llm_parse_date,\n",
    "    llm_interpret_yes_no,\n",
    "    llm_extract_symptoms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7081834",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:10,953] [INFO] Parsing date with LLM for input: last Tuesday during practice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Input: last Tuesday during practice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:12,002] [INFO] [OpenAI] Tokens used - Prompt: 155, Completion: 73, Total: 228\n",
      "[2025-04-16 15:28:12,002] [INFO] Parsed date: null, Certainty: low, Thought: Given that today is 2025-04-16, \"last Tuesday\" would be 2025-04-08 based on counting back from the current date. Since the user mentioned it happened during practice, we can assume it refers to a recent event. \n",
      "\n",
      "Therefore, the extracted date is: 2025-04-08 | certainty: high\n",
      "[2025-04-16 15:28:12,002] [INFO] Parsing date with LLM for input: March 5th\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': 'null', 'certainty': 'low', 'parsed_by': 'llm', 'original_input': 'last Tuesday during practice', 'thought': 'Given that today is 2025-04-16, \"last Tuesday\" would be 2025-04-08 based on counting back from the current date. Since the user mentioned it happened during practice, we can assume it refers to a recent event. \\n\\nTherefore, the extracted date is: 2025-04-08 | certainty: high'}\n",
      "\n",
      "üìù Input: March 5th\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:13,387] [INFO] [OpenAI] Tokens used - Prompt: 155, Completion: 138, Total: 293\n",
      "[2025-04-16 15:28:13,388] [INFO] Parsed date: 2025-05-28, Certainty: high, Thought: Since the user provided a specific date of March 5th without specifying the year, I will assume it is referring to March 5th of the current year (2025). To determine the full date, I will count the number of days between March 5th and today's date (April 16, 2025).\n",
      "\n",
      "March 5th to April 16th is 42 days.\n",
      "\n",
      "Adding 42 days to today's date:\n",
      "2025-04-16 + 42 days = 2025-05-28\n",
      "\n",
      "Therefore, the inferred date is May 28th, 2025.\n",
      "[2025-04-16 15:28:13,389] [INFO] Parsing date with LLM for input: a couple weeks ago\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': '2025-05-28', 'certainty': 'high', 'parsed_by': 'llm', 'original_input': 'March 5th', 'thought': \"Since the user provided a specific date of March 5th without specifying the year, I will assume it is referring to March 5th of the current year (2025). To determine the full date, I will count the number of days between March 5th and today's date (April 16, 2025).\\n\\nMarch 5th to April 16th is 42 days.\\n\\nAdding 42 days to today's date:\\n2025-04-16 + 42 days = 2025-05-28\\n\\nTherefore, the inferred date is May 28th, 2025.\"}\n",
      "\n",
      "üìù Input: a couple weeks ago\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:13,986] [INFO] [OpenAI] Tokens used - Prompt: 155, Completion: 41, Total: 196\n",
      "[2025-04-16 15:28:13,987] [INFO] Parsed date: 2025-04-01, Certainty: medium, Thought: \"A couple weeks ago\" from today's date of 2025-04-16 would approximately be around early April 2025.\n",
      "[2025-04-16 15:28:13,987] [INFO] Parsing date with LLM for input: on the weekend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': '2025-04-01', 'certainty': 'medium', 'parsed_by': 'llm', 'original_input': 'a couple weeks ago', 'thought': '\"A couple weeks ago\" from today\\'s date of 2025-04-16 would approximately be around early April 2025.'}\n",
      "\n",
      "üìù Input: on the weekend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:14,807] [INFO] [OpenAI] Tokens used - Prompt: 154, Completion: 70, Total: 224\n",
      "[2025-04-16 15:28:14,808] [INFO] Parsed date: 2025-04-19/2025-04-20, Certainty: high, Thought: Today is April 16, 2025, which is a Wednesday. \"On the weekend\" typically refers to the upcoming Saturday and Sunday. Therefore, the date would be April 19-20, 2025 (Saturday and Sunday).\n",
      "[2025-04-16 15:28:14,809] [INFO] Parsing date with LLM for input: sometime early April\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': '2025-04-19/2025-04-20', 'certainty': 'high', 'parsed_by': 'llm', 'original_input': 'on the weekend', 'thought': 'Today is April 16, 2025, which is a Wednesday. \"On the weekend\" typically refers to the upcoming Saturday and Sunday. Therefore, the date would be April 19-20, 2025 (Saturday and Sunday).'}\n",
      "\n",
      "üìù Input: sometime early April\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:15,665] [INFO] [OpenAI] Tokens used - Prompt: 154, Completion: 63, Total: 217\n",
      "[2025-04-16 15:28:15,666] [INFO] Parsed date: 2025-04-07, Certainty: medium, Thought: Based on today's date of 2025-04-16, \"early April\" would typically refer to the first week or two of April. Therefore, I will estimate the date as 2025-04-07 for early April.\n",
      "[2025-04-16 15:28:15,666] [INFO] Parsing date with LLM for input: don‚Äôt remember exactly, maybe mid-January\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': '2025-04-07', 'certainty': 'medium', 'parsed_by': 'llm', 'original_input': 'sometime early April', 'thought': 'Based on today\\'s date of 2025-04-16, \"early April\" would typically refer to the first week or two of April. Therefore, I will estimate the date as 2025-04-07 for early April.'}\n",
      "\n",
      "üìù Input: don‚Äôt remember exactly, maybe mid-January\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:16,547] [INFO] [OpenAI] Tokens used - Prompt: 160, Completion: 57, Total: 217\n",
      "[2025-04-16 15:28:16,548] [INFO] Parsed date: 2025-01-15, Certainty: medium, Thought: Based on today's date of 2025-04-16 and the user's mention of \"mid-January,\" we can estimate that the user is referring to around January 15th, 2025.\n",
      "[2025-04-16 15:28:16,549] [INFO] Parsing date with LLM for input: Friday night, after the second period\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': '2025-01-15', 'certainty': 'medium', 'parsed_by': 'llm', 'original_input': 'don‚Äôt remember exactly, maybe mid-January', 'thought': 'Based on today\\'s date of 2025-04-16 and the user\\'s mention of \"mid-January,\" we can estimate that the user is referring to around January 15th, 2025.'}\n",
      "\n",
      "üìù Input: Friday night, after the second period\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:18,555] [INFO] [OpenAI] Tokens used - Prompt: 158, Completion: 94, Total: 252\n",
      "[2025-04-16 15:28:18,556] [INFO] Parsed date: 2025-04-11, Certainty: medium, Thought: Based on today's date (2025-04-16), we can determine that Friday night would refer to the night of April 11, 2025, since Friday was April 11, 2025. However, since we don't have specific information about the second period, we cannot determine a precise date. Therefore, the estimated date would be April 11, 2025.\n",
      "[2025-04-16 15:28:18,557] [INFO] Parsing date with LLM for input: it was yesterday afternoon\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': '2025-04-11', 'certainty': 'medium', 'parsed_by': 'llm', 'original_input': 'Friday night, after the second period', 'thought': \"Based on today's date (2025-04-16), we can determine that Friday night would refer to the night of April 11, 2025, since Friday was April 11, 2025. However, since we don't have specific information about the second period, we cannot determine a precise date. Therefore, the estimated date would be April 11, 2025.\"}\n",
      "\n",
      "üìù Input: it was yesterday afternoon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:19,311] [INFO] [OpenAI] Tokens used - Prompt: 155, Completion: 39, Total: 194\n",
      "[2025-04-16 15:28:19,313] [INFO] Parsed date: 2025-04-15, Certainty: high, Thought: Yesterday afternoon relative to today's date (2025-04-16) would be 2025-04-15.\n",
      "[2025-04-16 15:28:19,313] [INFO] Parsing date with LLM for input: this morning before school\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': '2025-04-15', 'certainty': 'high', 'parsed_by': 'llm', 'original_input': 'it was yesterday afternoon', 'thought': \"Yesterday afternoon relative to today's date (2025-04-16) would be 2025-04-15.\"}\n",
      "\n",
      "üìù Input: this morning before school\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:20,130] [INFO] [OpenAI] Tokens used - Prompt: 155, Completion: 49, Total: 204\n",
      "[2025-04-16 15:28:20,131] [INFO] Parsed date: 2025-04-16, Certainty: high, Thought: Since today is 2025-04-16, \"this morning before school\" would typically refer to earlier today, which is still April 16, 2025.\n",
      "[2025-04-16 15:28:20,132] [INFO] Parsing date with LLM for input: late last month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': '2025-04-16', 'certainty': 'high', 'parsed_by': 'llm', 'original_input': 'this morning before school', 'thought': 'Since today is 2025-04-16, \"this morning before school\" would typically refer to earlier today, which is still April 16, 2025.'}\n",
      "\n",
      "üìù Input: late last month\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:20,906] [INFO] [OpenAI] Tokens used - Prompt: 154, Completion: 71, Total: 225\n",
      "[2025-04-16 15:28:20,907] [INFO] Parsed date: 2025-03-31, Certainty: high, Thought: \"Late last month\" refers to the period towards the end of the previous month. Since today is April 16, 2025, \"late last month\" would likely refer to late March 2025. Therefore, the inferred date is 2025-03-31.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': '2025-03-31', 'certainty': 'high', 'parsed_by': 'llm', 'original_input': 'late last month', 'thought': '\"Late last month\" refers to the period towards the end of the previous month. Since today is April 16, 2025, \"late last month\" would likely refer to late March 2025. Therefore, the inferred date is 2025-03-31.'}\n"
     ]
    }
   ],
   "source": [
    "inputs_dates = [\n",
    "    \"last Tuesday during practice\",\n",
    "    \"March 5th\",\n",
    "    \"a couple weeks ago\",\n",
    "    \"on the weekend\",\n",
    "    \"sometime early April\",\n",
    "    \"don‚Äôt remember exactly, maybe mid-January\",\n",
    "    \"Friday night, after the second period\",\n",
    "    \"it was yesterday afternoon\",\n",
    "    \"this morning before school\",\n",
    "    \"late last month\"\n",
    "]\n",
    "\n",
    "for text in inputs_dates:\n",
    "    print(f\"\\nüìù Input: {text}\")\n",
    "    print(llm_parse_date(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88cf4745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:20,916] [INFO] Interpreting yes/no response with LLM for input: yeah, I think so\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Input: yeah, I think so\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:21,666] [INFO] [OpenAI] Tokens used - Prompt: 301, Completion: 51, Total: 352\n",
      "[2025-04-16 15:28:21,668] [INFO] Parsed intent: partial, Certainty: medium, Thought: The user is leaning towards agreement with a slight indication of uncertainty. The use of \"yeah\" suggests agreement, while \"I think so\" introduces a bit of uncertainty. Overall, the response indicates a partial agreement.\n",
      "[2025-04-16 15:28:21,668] [INFO] Interpreting yes/no response with LLM for input: not really\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': 'partial', 'certainty': 'medium', 'parsed_by': 'llm', 'original_input': 'yeah, I think so', 'thought': 'The user is leaning towards agreement with a slight indication of uncertainty. The use of \"yeah\" suggests agreement, while \"I think so\" introduces a bit of uncertainty. Overall, the response indicates a partial agreement.'}\n",
      "\n",
      "üìù Input: not really\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:22,280] [INFO] [OpenAI] Tokens used - Prompt: 298, Completion: 33, Total: 331\n",
      "[2025-04-16 15:28:22,281] [INFO] Parsed intent: no, Certainty: high, Thought: The user explicitly expressed disagreement or denial by saying \"not really.\" This indicates the intent is 'no' with high certainty.\n",
      "[2025-04-16 15:28:22,282] [INFO] Interpreting yes/no response with LLM for input: absolutely\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': 'no', 'certainty': 'high', 'parsed_by': 'llm', 'original_input': 'not really', 'thought': 'The user explicitly expressed disagreement or denial by saying \"not really.\" This indicates the intent is \\'no\\' with high certainty.'}\n",
      "\n",
      "üìù Input: absolutely\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:22,896] [INFO] [OpenAI] Tokens used - Prompt: 297, Completion: 45, Total: 342\n",
      "[2025-04-16 15:28:22,897] [INFO] Parsed intent: yes, Certainty: high, Thought: The user's response \"absolutely\" indicates a strong agreement, showing a high level of certainty in their answer. Therefore, the intent is to say 'yes' with high certainty.\n",
      "[2025-04-16 15:28:22,898] [INFO] Interpreting yes/no response with LLM for input: I guess so\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': 'yes', 'certainty': 'high', 'parsed_by': 'llm', 'original_input': 'absolutely', 'thought': 'The user\\'s response \"absolutely\" indicates a strong agreement, showing a high level of certainty in their answer. Therefore, the intent is to say \\'yes\\' with high certainty.'}\n",
      "\n",
      "üìù Input: I guess so\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:23,713] [INFO] [OpenAI] Tokens used - Prompt: 299, Completion: 60, Total: 359\n",
      "[2025-04-16 15:28:23,715] [INFO] Parsed intent: yes, Certainty: medium, Thought: The user's response \"I guess so\" indicates a slight leaning towards agreement, but with some uncertainty. The use of \"guess\" implies hesitation or lack of complete confidence in the response. Therefore, the intent is leaning towards 'yes' with medium certainty.\n",
      "[2025-04-16 15:28:23,715] [INFO] Interpreting yes/no response with LLM for input: he didn‚Äôt mention it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': 'yes', 'certainty': 'medium', 'parsed_by': 'llm', 'original_input': 'I guess so', 'thought': 'The user\\'s response \"I guess so\" indicates a slight leaning towards agreement, but with some uncertainty. The use of \"guess\" implies hesitation or lack of complete confidence in the response. Therefore, the intent is leaning towards \\'yes\\' with medium certainty.'}\n",
      "\n",
      "üìù Input: he didn‚Äôt mention it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:24,634] [INFO] [OpenAI] Tokens used - Prompt: 301, Completion: 63, Total: 364\n",
      "[2025-04-16 15:28:24,635] [INFO] Parsed intent: uncertain, Certainty: high, Thought: The user mentioned that \"he didn‚Äôt mention it,\" indicating missing information or uncertainty about the topic. There is no explicit denial or agreement present in the response. Therefore, the intent is uncertain. The certainty is high because the user clearly stated that the information was not provided.\n",
      "[2025-04-16 15:28:24,636] [INFO] Interpreting yes/no response with LLM for input: nope\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': 'uncertain', 'certainty': 'high', 'parsed_by': 'llm', 'original_input': 'he didn‚Äôt mention it', 'thought': 'The user mentioned that \"he didn‚Äôt mention it,\" indicating missing information or uncertainty about the topic. There is no explicit denial or agreement present in the response. Therefore, the intent is uncertain. The certainty is high because the user clearly stated that the information was not provided.'}\n",
      "\n",
      "üìù Input: nope\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:25,251] [INFO] [OpenAI] Tokens used - Prompt: 298, Completion: 32, Total: 330\n",
      "[2025-04-16 15:28:25,252] [INFO] Parsed intent: no, Certainty: high, Thought: The user explicitly expressed disagreement with a straightforward \"nope.\" Therefore, the intent is 'no' with high certainty.\n",
      "[2025-04-16 15:28:25,253] [INFO] Interpreting yes/no response with LLM for input: probably not\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': 'no', 'certainty': 'high', 'parsed_by': 'llm', 'original_input': 'nope', 'thought': 'The user explicitly expressed disagreement with a straightforward \"nope.\" Therefore, the intent is \\'no\\' with high certainty.'}\n",
      "\n",
      "üìù Input: probably not\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:25,966] [INFO] [OpenAI] Tokens used - Prompt: 298, Completion: 48, Total: 346\n",
      "[2025-04-16 15:28:25,968] [INFO] Parsed intent: no, Certainty: medium, Thought: The user expressed a leaning towards disagreement by saying \"probably not,\" which indicates a negative stance. The certainty is medium due to the use of the word \"probably,\" which suggests some level of uncertainty.\n",
      "[2025-04-16 15:28:25,968] [INFO] Interpreting yes/no response with LLM for input: yes, but only for a bit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': 'no', 'certainty': 'medium', 'parsed_by': 'llm', 'original_input': 'probably not', 'thought': 'The user expressed a leaning towards disagreement by saying \"probably not,\" which indicates a negative stance. The certainty is medium due to the use of the word \"probably,\" which suggests some level of uncertainty.'}\n",
      "\n",
      "üìù Input: yes, but only for a bit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:26,893] [INFO] [OpenAI] Tokens used - Prompt: 303, Completion: 62, Total: 365\n",
      "[2025-04-16 15:28:26,894] [INFO] Parsed intent: partial, Certainty: medium, Thought: The user is expressing a partial agreement by saying \"yes, but only for a bit.\" This indicates that they agree to some extent, but only for a limited duration or under certain conditions. The user's certainty is medium as they are not fully committed to the agreement.\n",
      "[2025-04-16 15:28:26,895] [INFO] Interpreting yes/no response with LLM for input: no, he was fine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': 'partial', 'certainty': 'medium', 'parsed_by': 'llm', 'original_input': 'yes, but only for a bit', 'thought': 'The user is expressing a partial agreement by saying \"yes, but only for a bit.\" This indicates that they agree to some extent, but only for a limited duration or under certain conditions. The user\\'s certainty is medium as they are not fully committed to the agreement.'}\n",
      "\n",
      "üìù Input: no, he was fine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:27,605] [INFO] [OpenAI] Tokens used - Prompt: 301, Completion: 31, Total: 332\n",
      "[2025-04-16 15:28:27,606] [INFO] Parsed intent: no, Certainty: high, Thought: The user explicitly expressed disagreement or denial by saying \"no.\" There is a high level of certainty in their response.\n",
      "[2025-04-16 15:28:27,607] [INFO] Interpreting yes/no response with LLM for input: I‚Äôm not sure, maybe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': 'no', 'certainty': 'high', 'parsed_by': 'llm', 'original_input': 'no, he was fine', 'thought': 'The user explicitly expressed disagreement or denial by saying \"no.\" There is a high level of certainty in their response.'}\n",
      "\n",
      "üìù Input: I‚Äôm not sure, maybe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:28,425] [INFO] [OpenAI] Tokens used - Prompt: 302, Completion: 49, Total: 351\n",
      "[2025-04-16 15:28:28,426] [INFO] Parsed intent: uncertain, Certainty: low, Thought: The user's response indicates uncertainty as they express doubt and hesitation by saying \"I‚Äôm not sure, maybe\". The user is not leaning towards a clear yes or no but rather is unsure about the answer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': 'uncertain', 'certainty': 'low', 'parsed_by': 'llm', 'original_input': 'I‚Äôm not sure, maybe', 'thought': 'The user\\'s response indicates uncertainty as they express doubt and hesitation by saying \"I‚Äôm not sure, maybe\". The user is not leaning towards a clear yes or no but rather is unsure about the answer.'}\n"
     ]
    }
   ],
   "source": [
    "inputs_yesno = [\n",
    "    \"yeah, I think so\",\n",
    "    \"not really\",\n",
    "    \"absolutely\",\n",
    "    \"I guess so\",\n",
    "    \"he didn‚Äôt mention it\",\n",
    "    \"nope\",\n",
    "    \"probably not\",\n",
    "    \"yes, but only for a bit\",\n",
    "    \"no, he was fine\",\n",
    "    \"I‚Äôm not sure, maybe\"\n",
    "]\n",
    "\n",
    "for text in inputs_yesno:\n",
    "    print(f\"\\nüìù Input: {text}\")\n",
    "    print(llm_interpret_yes_no(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7946d506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:28,434] [INFO] Extracting symptoms with LLM for input: he said he had a pounding headache and felt foggy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Input: he said he had a pounding headache and felt foggy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:29,345] [INFO] [OpenAI] Tokens used - Prompt: 176, Completion: 57, Total: 233\n",
      "[2025-04-16 15:28:29,345] [INFO] Parsed symptoms: ['headache', 'confusion'], Certainty: high, Thought: I am confident in extracting the following symptoms:\n",
      "- headache\n",
      "- confusion\n",
      "\n",
      "Reasoning: The user explicitly mentioned a \"pounding headache\" and feeling \"foggy,\" which indicates symptoms of headache and confusion.\n",
      "[2025-04-16 15:28:29,346] [INFO] Extracting symptoms with LLM for input: just seemed off, kind of dizzy and out of it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': ['headache', 'confusion'], 'certainty': 'high', 'parsed_by': 'llm', 'original_input': 'he said he had a pounding headache and felt foggy', 'thought': 'I am confident in extracting the following symptoms:\\n- headache\\n- confusion\\n\\nReasoning: The user explicitly mentioned a \"pounding headache\" and feeling \"foggy,\" which indicates symptoms of headache and confusion.'}\n",
      "\n",
      "üìù Input: just seemed off, kind of dizzy and out of it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:30,286] [INFO] [OpenAI] Tokens used - Prompt: 176, Completion: 68, Total: 244\n",
      "[2025-04-16 15:28:30,287] [INFO] Parsed symptoms: ['dizzy', 'confusion'], Certainty: high, Thought: I am confident in extracting the symptoms \"dizzy\" and \"out of it\" from the user's input. The description \"kind of dizzy\" clearly indicates dizziness, and \"out of it\" can imply confusion or disorientation, which are common concussion symptoms.\n",
      "[2025-04-16 15:28:30,288] [INFO] Extracting symptoms with LLM for input: said her vision was blurry for a few minutes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': ['dizzy', 'confusion'], 'certainty': 'high', 'parsed_by': 'llm', 'original_input': 'just seemed off, kind of dizzy and out of it', 'thought': 'I am confident in extracting the symptoms \"dizzy\" and \"out of it\" from the user\\'s input. The description \"kind of dizzy\" clearly indicates dizziness, and \"out of it\" can imply confusion or disorientation, which are common concussion symptoms.'}\n",
      "\n",
      "üìù Input: said her vision was blurry for a few minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:31,149] [INFO] [OpenAI] Tokens used - Prompt: 174, Completion: 60, Total: 234\n",
      "[2025-04-16 15:28:31,150] [INFO] Parsed symptoms: ['blurry vision'], Certainty: high, Thought: I have identified the symptom \"blurry vision\" from the user's input. Blurry vision is a common symptom associated with concussions. I am confident in this extraction because the user clearly mentioned experiencing blurry vision for a few minutes.\n",
      "[2025-04-16 15:28:31,151] [INFO] Extracting symptoms with LLM for input: he complained of ringing in his ears and nausea\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': ['blurry vision'], 'certainty': 'high', 'parsed_by': 'llm', 'original_input': 'said her vision was blurry for a few minutes', 'thought': 'I have identified the symptom \"blurry vision\" from the user\\'s input. Blurry vision is a common symptom associated with concussions. I am confident in this extraction because the user clearly mentioned experiencing blurry vision for a few minutes.'}\n",
      "\n",
      "üìù Input: he complained of ringing in his ears and nausea\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:32,006] [INFO] [OpenAI] Tokens used - Prompt: 174, Completion: 56, Total: 230\n",
      "[2025-04-16 15:28:32,007] [INFO] Parsed symptoms: ['ringing in ears', 'nausea'], Certainty: high, Thought: I identified the following symptoms:\n",
      "- ringing in ears\n",
      "- nausea\n",
      "\n",
      "Reasoning: The user clearly mentioned two symptoms: ringing in the ears and nausea. These are common symptoms associated with a concussion.\n",
      "[2025-04-16 15:28:32,007] [INFO] Extracting symptoms with LLM for input: I noticed she was acting slow and confused\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': ['ringing in ears', 'nausea'], 'certainty': 'high', 'parsed_by': 'llm', 'original_input': 'he complained of ringing in his ears and nausea', 'thought': 'I identified the following symptoms:\\n- ringing in ears\\n- nausea\\n\\nReasoning: The user clearly mentioned two symptoms: ringing in the ears and nausea. These are common symptoms associated with a concussion.'}\n",
      "\n",
      "üìù Input: I noticed she was acting slow and confused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:32,827] [INFO] [OpenAI] Tokens used - Prompt: 173, Completion: 26, Total: 199\n",
      "[2025-04-16 15:28:32,828] [INFO] Parsed symptoms: ['confusion'], Certainty: medium, Thought: I identified the following symptoms:\n",
      "- confusion\n",
      "\n",
      "Confidence: medium\n",
      "[2025-04-16 15:28:32,828] [INFO] Extracting symptoms with LLM for input: he just looked dazed and didn‚Äôt answer right away\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': ['confusion'], 'certainty': 'medium', 'parsed_by': 'llm', 'original_input': 'I noticed she was acting slow and confused', 'thought': 'I identified the following symptoms:\\n- confusion\\n\\nConfidence: medium'}\n",
      "\n",
      "üìù Input: he just looked dazed and didn‚Äôt answer right away\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:33,799] [INFO] [OpenAI] Tokens used - Prompt: 176, Completion: 62, Total: 238\n",
      "[2025-04-16 15:28:33,799] [INFO] Parsed symptoms: [], Certainty: low, Thought: I didn't find any specific symptoms mentioned in this input. The description \"looked dazed\" could indicate confusion, but it's not explicitly mentioned. The delay in answering could also imply confusion, but it's not definitive. Therefore, the certainty is low.\n",
      "[2025-04-16 15:28:33,800] [INFO] Extracting symptoms with LLM for input: head hurt, felt tired, didn‚Äôt want to skate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': [], 'certainty': 'low', 'parsed_by': 'llm', 'original_input': 'he just looked dazed and didn‚Äôt answer right away', 'thought': 'I didn\\'t find any specific symptoms mentioned in this input. The description \"looked dazed\" could indicate confusion, but it\\'s not explicitly mentioned. The delay in answering could also imply confusion, but it\\'s not definitive. Therefore, the certainty is low.'}\n",
      "\n",
      "üìù Input: head hurt, felt tired, didn‚Äôt want to skate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:34,873] [INFO] [OpenAI] Tokens used - Prompt: 176, Completion: 52, Total: 228\n",
      "[2025-04-16 15:28:34,874] [INFO] Parsed symptoms: ['headache', 'fatigue'], Certainty: high, Thought: I identified the following symptoms:\n",
      "- headache\n",
      "- fatigue\n",
      "\n",
      "I am confident in this extraction as the user clearly mentioned the head hurting and feeling tired, which are common symptoms of a concussion.\n",
      "[2025-04-16 15:28:34,874] [INFO] Extracting symptoms with LLM for input: felt okay at first, but later had a headache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': ['headache', 'fatigue'], 'certainty': 'high', 'parsed_by': 'llm', 'original_input': 'head hurt, felt tired, didn‚Äôt want to skate', 'thought': 'I identified the following symptoms:\\n- headache\\n- fatigue\\n\\nI am confident in this extraction as the user clearly mentioned the head hurting and feeling tired, which are common symptoms of a concussion.'}\n",
      "\n",
      "üìù Input: felt okay at first, but later had a headache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:35,704] [INFO] [OpenAI] Tokens used - Prompt: 175, Completion: 56, Total: 231\n",
      "[2025-04-16 15:28:35,705] [INFO] Parsed symptoms: ['headache'], Certainty: medium, Thought: I identified the symptom:\n",
      "- headache\n",
      "\n",
      "Confidence: medium\n",
      "\n",
      "The user clearly mentioned experiencing a headache, but there is no mention of any other symptoms related to concussion. Therefore, I am moderately confident in my extraction.\n",
      "[2025-04-16 15:28:35,706] [INFO] Extracting symptoms with LLM for input: she seemed fine, maybe just tired\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': ['headache'], 'certainty': 'medium', 'parsed_by': 'llm', 'original_input': 'felt okay at first, but later had a headache', 'thought': 'I identified the symptom:\\n- headache\\n\\nConfidence: medium\\n\\nThe user clearly mentioned experiencing a headache, but there is no mention of any other symptoms related to concussion. Therefore, I am moderately confident in my extraction.'}\n",
      "\n",
      "üìù Input: she seemed fine, maybe just tired\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:36,513] [INFO] [OpenAI] Tokens used - Prompt: 172, Completion: 48, Total: 220\n",
      "[2025-04-16 15:28:36,514] [INFO] Parsed symptoms: [], Certainty: low, Thought: I did not detect any specific concussion symptoms mentioned in the user's input. The user only mentioned that the person seemed fine, possibly just tired. Therefore, I have low certainty in my extraction.\n",
      "[2025-04-16 15:28:36,515] [INFO] Extracting symptoms with LLM for input: had a mild headache but said she was fine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': [], 'certainty': 'low', 'parsed_by': 'llm', 'original_input': 'she seemed fine, maybe just tired', 'thought': \"I did not detect any specific concussion symptoms mentioned in the user's input. The user only mentioned that the person seemed fine, possibly just tired. Therefore, I have low certainty in my extraction.\"}\n",
      "\n",
      "üìù Input: had a mild headache but said she was fine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 15:28:37,024] [INFO] [OpenAI] Tokens used - Prompt: 174, Completion: 22, Total: 196\n",
      "[2025-04-16 15:28:37,026] [INFO] Parsed symptoms: ['headache'], Certainty: medium, Thought: I identified the symptom:\n",
      "- headache\n",
      "\n",
      "Confidence: medium\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': ['headache'], 'certainty': 'medium', 'parsed_by': 'llm', 'original_input': 'had a mild headache but said she was fine', 'thought': 'I identified the symptom:\\n- headache\\n\\nConfidence: medium'}\n"
     ]
    }
   ],
   "source": [
    "inputs_symptoms = [\n",
    "    \"he said he had a pounding headache and felt foggy\",\n",
    "    \"just seemed off, kind of dizzy and out of it\",\n",
    "    \"said her vision was blurry for a few minutes\",\n",
    "    \"he complained of ringing in his ears and nausea\",\n",
    "    \"I noticed she was acting slow and confused\",\n",
    "    \"he just looked dazed and didn‚Äôt answer right away\",\n",
    "    \"head hurt, felt tired, didn‚Äôt want to skate\",\n",
    "    \"felt okay at first, but later had a headache\",\n",
    "    \"she seemed fine, maybe just tired\",\n",
    "    \"had a mild headache but said she was fine\"\n",
    "]\n",
    "\n",
    "for text in inputs_symptoms:\n",
    "    print(f\"\\nüìù Input: {text}\")\n",
    "    print(llm_extract_symptoms(text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spaCy 3.11)",
   "language": "python",
   "name": "spacy_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
